{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Live cu-inj-live-impact "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"LCLS_LATTICE\"] = \"/sdf/group/ad/sw/scm/repos/optics/lcls-lattice/\"\n",
    "\n",
    "os.environ[\"LCLS_LATTICE\"] = \"/sdf/group/ad/sw/scm/repos/optics/lcls-lattice/\"\n",
    "os.environ[\"SCRATCH\"]=\"/sdf/home/m/mokun/SCRATCH\"\n",
    "os.environ[\"LUME_IMPACT_CODEBASE_LOCATION\"]=\"/sdf/home/m/mokun/code/lume-repos/lume-impact-live-demo\"\n",
    "os.environ[\"LUME_OUTPUT_FOLDERS\"]=\"/sdf/home/m/mokun/lume-output\"\n",
    "\n",
    "# Use Default PVA PORT numbers\n",
    "os.environ[\"EPICS_PVA_SERVER_PORT\"]=\"5075\"\n",
    "os.environ[\"EPICS_PVA_BROADCAST_PORT\"]=\"5076\"\n",
    "\n",
    "# Use explicit EPICS_PVA_ADDR_LIST\n",
    "os.environ[\"EPICS_PVA_AUTO_ADDR_LIST\"]=\"NO\"\n",
    "# NOTE: PVA Gateway not setup as of 11/1/2019.  Recheck settings on PVA gateway deployment\n",
    "# Gateway to PROD, st.gwLCLSPUB\n",
    "os.environ[\"EPICS_PVA_ADDR_LIST\"]=\"lcls-prod01:5068\"\n",
    "# Gateway st.gwEXP2FACET\n",
    "os.environ[\"EPICS_PVA_ADDR_LIST\"]=\"${EPICS_PVA_ADDR_LIST} lcls-prod01:5063\"\n",
    "# Add mcc-dmz and mccas0\n",
    "os.environ[\"EPICS_PVA_ADDR_LIST\"]=\"${EPICS_PVA_ADDR_LIST} mcc-dmz mccas0.slac.stanford.edu\"\n",
    "\n",
    "os.environ[\"EPICS_CA_AUTO_ADDR_LIST\"]=\"NO\"\n",
    "os.environ[\"EPICS_CA_ADDR_LIST\"]=\"lcls-prod01:5068 lcls-prod01:5063 mcc-dmz\"\n",
    "os.environ[\"EPICS_CA_REPEATER_PORT\"]=\"5069\"\n",
    "os.environ[\"EPICS_CA_SERVER_PORT\"]=\"5068\"\n",
    "\n",
    "os.environ[\"EPICS_TS_NTP_INET\"]=\"134.79.48.11\"\n",
    "os.environ[\"EPICS_IOC_LOG_INET\"]=\"134.79.151.21\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup directories, and convert dashboard notebook to a script for importing\n",
    "#!./setup.bash\n",
    "print(\"Running LUME IMPACT SERVICE.....\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from impact import evaluate_impact_with_distgen, run_impact_with_distgen\n",
    "from impact.tools import isotime\n",
    "from impact.evaluate import  default_impact_merit\n",
    "from impact import Impact\n",
    "\n",
    "from make_dashboard import make_dashboard\n",
    "from get_vcc_image import get_live_distgen_xy_dist, VCC_DEVICE_PV\n",
    "\n",
    "from lcls_live.tools import NpEncoder\n",
    "\n",
    "import matplotlib as mpl\n",
    "\n",
    "from pmd_beamphysics.units import e_charge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import h5py\n",
    "import json\n",
    "import epics\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import toml\n",
    "from time import sleep, time\n",
    "import datetime\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import matplotlib as mpl\n",
    "mpl.use('Agg')\n",
    "\n",
    "# Nicer plotting\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sanity Checks for OS Environments\n",
    "if 'LCLS_LATTICE' in os.environ:\n",
    "    print('LCLS Lattice is set to - ', os.environ['LCLS_LATTICE'])\n",
    "else:\n",
    "    print('LCLS_LATTICE Location is missing')\n",
    "    exit(1)\n",
    "if 'LUME_OUTPUT_FOLDERS' in os.environ:\n",
    "    print('LUME_OUTPUT_FOLDERS is set to - ', os.environ['LUME_OUTPUT_FOLDERS'])\n",
    "else:\n",
    "    print('LUME_OUTPUT_FOLDERS Location is missing')\n",
    "    exit(1)\n",
    "if 'SCRATCH' in os.environ:\n",
    "    print('SCRATCH is set to - ', os.environ['SCRATCH'])\n",
    "else:\n",
    "    print('SCRATCH Location is missing')\n",
    "    exit(1)\n",
    "\n",
    "def replaceEnvironmentFiles(file_location):\n",
    "    if 'LUME_OUTPUT_FOLDERS' in file_location:\n",
    "        return file_location.replace('$LUME_OUTPUT_FOLDERS', os.environ['LUME_OUTPUT_FOLDERS'])\n",
    "    if 'LCLS_LATTICE' in file_location:\n",
    "        return file_location.replace('$LCLS_LATTICE', os.environ['LCLS_LATTICE'])\n",
    "    if 'SCRATCH' in file_location:\n",
    "        return file_location.replace('$SCRATCH', os.environ['SCRATCH'])\n",
    "    return file_location"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top level config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"-d\", \"--debug\", help = \"Debug Mode\", default = False)\n",
    "parser.add_argument(\"-v\", \"--use_vcc\", help = \"Use VCC - True When VCC is Active\", default = True)\n",
    "parser.add_argument(\"-l\", \"--live\", help = \"Live Mode -  True When BEAM is Active\", default = True)\n",
    "parser.add_argument(\"-m\", \"--model\", help = \"Mention the Injector Model\", default = \"sc_inj\")\n",
    "parser.add_argument(\"-t\", \"--host\", help = \"Mention the host\", default = \"singularity\")\n",
    "parser.add_argument(\"-p\", \"--num_procs\", help = \"Mention the Num Procs\", default = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertStringToBoolean(argument):\n",
    "    if argument == 'True' or argument == 'true' or argument == True:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#args = vars(parser.parse_args())\n",
    "\n",
    "#DEBUG = convertStringToBoolean(args['debug'])\n",
    "#USE_VCC = convertStringToBoolean(args['use_vcc'])\n",
    "#LIVE = convertStringToBoolean(args['live'])\n",
    "#MODEL = args['model']\n",
    "#HOST = args['host']\n",
    "#NUM_PROCS_ARGS = int(args['num_procs'])\n",
    "DEBUG = False\n",
    "USE_VCC = True\n",
    "USE_SAVED_VCC = False\n",
    "SAVED_VCC = \"/sdf/group/ad/beamphysics/jytang/lume-impact-live-demo/configs/vcc_image/laser_06032024.txt\"\n",
    "LIVE = True\n",
    "MODEL = \"sc_inj\"\n",
    "HOST = 's3df'\n",
    "NUM_PROCS_ARGS = 64\n",
    "\n",
    "SNAPSHOT = 'examples/sc_inj-snapshot-2022-11-12T12:38:08-08:00.h5'\n",
    "MIN_CHARGE_pC = 10\n",
    "config = toml.load(f\"configs/{HOST}_{MODEL}.toml\")\n",
    "PREFIX = f'lume-impact-live-demo-{HOST}-{MODEL}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertToDatedFormat(destionation_folder):\n",
    "    curr_date = datetime.date.today()\n",
    "    year,month,day = curr_date.strftime('%Y'),curr_date.strftime('%m'),curr_date.strftime('%d')\n",
    "    destionation_folder_dated = destionation_folder + \"/\" + year + \"/\" + month + \"/\" + day\n",
    "\n",
    "    if not os.path.exists(destionation_folder_dated):\n",
    "        os.makedirs(destionation_folder_dated)\n",
    "    \n",
    "    return destionation_folder_dated"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from logging.handlers import RotatingFileHandler\n",
    "\n",
    "# Gets or creates a logger\n",
    "logger = logging.getLogger(PREFIX)  \n",
    "\n",
    "# set log level\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "LOG_OUTPUT_DIR = config.get(\"log_output_dir\")\n",
    "LOG_OUTPUT_DIR = replaceEnvironmentFiles(LOG_OUTPUT_DIR)\n",
    "# define file handler and set formatter\n",
    "file_handler = RotatingFileHandler(f'{LOG_OUTPUT_DIR}/{PREFIX}.log', mode='a', encoding=None, maxBytes=50*1024*1024, \n",
    "                                 backupCount=2, delay=0)\n",
    "formatter    = logging.Formatter(fmt=\"%(asctime)s :  %(name)s : %(message)s \", datefmt=\"%Y-%m-%dT%H:%M:%S%z\")\n",
    "\n",
    "# Add print to stdout\n",
    "logger.addHandler(logging.StreamHandler(sys.stdout))\n",
    "\n",
    "file_handler.setFormatter(formatter)\n",
    "\n",
    "# add file handler to logger\n",
    "logger.addHandler(file_handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Arguments -\n",
    "\n",
    "logger.info('Start of Script Marker - Script Running with Arguments - ')\n",
    "logger.info(f'Debug - {DEBUG}')\n",
    "logger.info(f'USE_VCC - {USE_VCC}')\n",
    "logger.info(f'LIVE - {LIVE}')\n",
    "logger.info(f'MODEL - {MODEL}')\n",
    "logger.info(f'HOST - {HOST}')\n",
    "logger.info(f'NUM_PROCS_ARGS - {NUM_PROCS_ARGS}')\n",
    "logger.info(f'Config TOML Loaded - {config}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving and loading\n",
    "def save_pvdata(filename, pvdata, isotime):\n",
    "    with h5py.File(filename, 'w') as h5:\n",
    "        h5.attrs['isotime'] = np.bytes_(isotime)\n",
    "        for k, v in pvdata.items():\n",
    "            if isinstance(v, str):\n",
    "                v =  np.bytes_(v)\n",
    "            h5[k] = v \n",
    "def load_pvdata(filename):\n",
    "    \n",
    "    if not os.path.exists(filename):\n",
    "        raise ValueError(f'H5 file does not exist: {filename} ')\n",
    "    pvdata = {}\n",
    "    with h5py.File(filename, 'r') as h5:\n",
    "        isotime = h5.attrs['isotime']\n",
    "        for k in h5:\n",
    "            v = np.array(h5[k])        \n",
    "            if v.dtype.char == 'S':\n",
    "                v = str(v.astype(str))\n",
    "            pvdata[k] = v\n",
    "            \n",
    "    return pvdata, isotime"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration\n",
    "\n",
    "Set up basic input sources and output path, loaded from toml environment file.\n",
    "\n",
    "See README for required toml definition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HOST = config.get('host') # mcc-simul or 'sdf'\n",
    "if not HOST:\n",
    "    raise ValueError(\"host not defined in toml.\")\n",
    "    \n",
    "def get_path(key):\n",
    "    val = config.get(key)\n",
    "    if not val:\n",
    "        raise ValueError(f\"{key} not defined in toml.\")\n",
    "    val=os.path.expandvars(val)\n",
    "    if not os.path.exists(val):\n",
    "        raise ValueError(f\"{val} does not exist\")\n",
    "    return os.path.abspath(val)\n",
    "\n",
    "\n",
    "# Output dirs\n",
    "\n",
    "SUMMARY_OUTPUT_DIR = replaceEnvironmentFiles(get_path('summary_output_dir'))\n",
    "ARCHIVE_DIR = replaceEnvironmentFiles(get_path('archive_dir'))\n",
    "SNAPSHOT_DIR = replaceEnvironmentFiles(get_path('snapshot_dir'))\n",
    "\n",
    "# Dummy file for distgen\n",
    "DISTGEN_LASER_FILE = config.get('distgen_laser_file')\n",
    "if not DISTGEN_LASER_FILE:\n",
    "    raise ValueError(\"distgen_laser_file not defined in toml.\")\n",
    "\n",
    "# Number of processors\n",
    "NUM_PROCS = config.get('num_procs')\n",
    "if not NUM_PROCS:\n",
    "    raise ValueError(\"num_procs not defined in toml.\")\n",
    "else:\n",
    "    NUM_PROCS = int(NUM_PROCS)\n",
    "\n",
    "if NUM_PROCS_ARGS != NUM_PROCS:\n",
    "    NUM_PROCS = NUM_PROCS_ARGS\n",
    "\n",
    "# if using sdf:\n",
    "if HOST == 'sdf':    \n",
    "    #check that environment variables are configured for execution\n",
    "    IMPACT_COMMAND = config.get(\"impact_command\")\n",
    "    if not IMPACT_COMMAND:\n",
    "       raise ValueError(\"impact_command not defined in toml.\")\n",
    "\n",
    "\n",
    "    IMPACT_COMMAND_MPI = config.get(\"impact_command_mpi\")\n",
    "    if not IMPACT_COMMAND_MPI:\n",
    "       raise ValueError(\"impact_command_mpi not defined in toml.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG0 = {}\n",
    "\n",
    "# Base settings\n",
    "SETTINGS0 = {\n",
    " 'distgen:n_particle': 10_000,   \n",
    " 'timeout': 10000,\n",
    " 'header:Nx': 32,\n",
    " 'header:Ny': 32,\n",
    " 'header:Nz': 32,\n",
    " 'numprocs': NUM_PROCS,\n",
    "   }\n",
    "\n",
    "SETTINGS0['numprocs'] = NUM_PROCS\n",
    "CONFIG0[\"workdir\"] = replaceEnvironmentFiles(get_path('workdir'))\n",
    "\n",
    "if DEBUG:\n",
    "    logger.info('DEBUG MODE: Running without space charge for speed. ')\n",
    "    SETTINGS0['distgen:n_particle'] = 1000\n",
    "    SETTINGS0['total_charge'] = 0\n",
    "    \n",
    "# Host config    \n",
    "if HOST in ('sdf'):\n",
    "    \n",
    "    #SDF setup \n",
    "    SETTINGS0['command'] =  IMPACT_COMMAND\n",
    "    SETTINGS0['command_mpi'] =  IMPACT_COMMAND_MPI\n",
    "    SETTINGS0['mpi_run'] = config.get(\"mpi_run_cmd\")\n",
    "    \n",
    "elif HOST == 'local':\n",
    "    logger.info('Running locally')\n",
    "    \n",
    "else:\n",
    "    raise ValueError(f'Unknown host: {HOST}')\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select: LCLS or FACET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PV -> Sim conversion table\n",
    "CSV =  f'pv_mapping/{MODEL}_impact.csv'  \n",
    "\n",
    "CONFIG0['impact_config']      =  replaceEnvironmentFiles(get_path('config_file'))\n",
    "CONFIG0['distgen_input_file'] =  replaceEnvironmentFiles(get_path('distgen_input_file'))\n",
    "\n",
    "print('Impact Config Loaded - ', CONFIG0['impact_config'] )\n",
    "print('Distgen Input File Loaded - ', CONFIG0['distgen_input_file'] )\n",
    "\n",
    "PLOT_OUTPUT_DIR = replaceEnvironmentFiles(get_path('plot_output_dir'))\n",
    "\n",
    "if MODEL == 'cu_inj':\n",
    "    VCC_DEVICE = 'CAMR:IN20:186' # LCLS   \n",
    "    \n",
    "    DASHBOARD_KWARGS = {'outpath':PLOT_OUTPUT_DIR,\n",
    "                    'screen1': 'YAG02',\n",
    "                    'screen2': 'YAG03',\n",
    "                    'screen3': 'OTR2',\n",
    "                    'ylim' : (0, None), # Emittance scale   \n",
    "                    'ylim2': (0, None), # sigma_x scale\n",
    "                    'name' : PREFIX\n",
    "                   }    \n",
    "    \n",
    "    SETTINGS0['stop'] = 16.5\n",
    "    SETTINGS0['distgen:t_dist:length:value'] =  4 * 1.65   #  Inferred pulse stacker FWHM: 4 ps, converted to tukey length\n",
    "    \n",
    "if MODEL == 'sc_inj':\n",
    "    VCC_DEVICE = 'CAMR:LGUN:950' # LCLS-II \n",
    "    \n",
    "    DASHBOARD_KWARGS = {'outpath':PLOT_OUTPUT_DIR,\n",
    "                    'screen1': 'YAG01B',\n",
    "                  #  'screen2': 'BEAM0',\n",
    "                  #  'screen3': 'OTR0H04',\n",
    "                    'screen2': 'CM01BEG',\n",
    "                    'screen3': 'BEAM0',\n",
    "                    'ylim' : (0, 3e-6), # Emittance scale   \n",
    "                    'ylim2': (0, None), # sigma_x scale                    \n",
    "                    'name' : PREFIX\n",
    "                   }    \n",
    "    \n",
    "    SETTINGS0['stop'] = 14 # 28\n",
    "    SETTINGS0['distgen:t_dist:sigma_t:value'] =  16 / 2.355   # ps, equivalent to 16ps FWHM from Feng\n",
    "    \n",
    "elif MODEL == 'f2e_inj':\n",
    "    VCC_DEVICE = 'CAMR:LT10:900' # FACET-II\n",
    "    \n",
    "    DASHBOARD_KWARGS = {'outpath':PLOT_OUTPUT_DIR,\n",
    "                    'screen1': 'PR10241',\n",
    "                    'screen2': 'PR10465',\n",
    "                    'screen3': 'PR10571',\n",
    "                    'ylim' : (0, 20e-6), # Emittance scale\n",
    "                    'name' : PREFIX\n",
    "                   }        \n",
    "    \n",
    "    SETTINGS0['distgen:t_dist:length:value'] =  3.65 * 1.65   #  Measured FWHM: 3.65 ps, converted to tukey length\n",
    "     \n",
    "else:\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG0, SETTINGS0\n",
    "logger.info(f'FINAL SETTINGS - {SETTINGS0}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up monitors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gun: 700 kV\n",
    "# Buncher: 200 keV energy gain\n",
    "# Buncher: +60 deg relative to on-crest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF = pd.read_csv(CSV)#.dropna()\n",
    "\n",
    "PVLIST = list(DF['device_pv_name'].dropna()) \n",
    "\n",
    "if USE_VCC:\n",
    "    PVLIST = PVLIST + list(VCC_DEVICE_PV[VCC_DEVICE].values())\n",
    "else:\n",
    "    logger.info('USE VCC set to False. VCC is not working right now.')\n",
    "#DF.set_index('device_pv_name', inplace=True)\n",
    "DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if LIVE:\n",
    "    MONITOR = {pvname:epics.PV(pvname) for pvname in PVLIST}\n",
    "    SNAPSHOT = None\n",
    "    sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_snapshot(snapshot_file=None):\n",
    "        \n",
    "    if LIVE:\n",
    "        itime = isotime()\n",
    "        pvdata =  {k:MONITOR[k].get() for k in MONITOR}\n",
    "    else:\n",
    "        pvdata, itime = load_pvdata(snapshot_file)\n",
    "        itime = itime.decode('utf-8')\n",
    "    \n",
    "    logger.info(f'Acquired settings from EPICS at: {itime}')\n",
    "    \n",
    "    epics_working_check = [val for val in pvdata.values() if val is None]\n",
    "    \n",
    "    if len(epics_working_check) == len(list(pvdata.keys())):\n",
    "        raise Exception(f'EPICS returned None for all keys. Please check if you are able to connect to Accelerator')\n",
    "\n",
    "    VCC_Key = None\n",
    "    \n",
    "    for k, v in pvdata.items():\n",
    "        \n",
    "        if v is None:\n",
    "            raise ValueError(f'EPICS get for {k} returned None')\n",
    "        \n",
    "        if ':IMAGE:ARRAYDATA' in k.upper():\n",
    "            VCC_Key = k\n",
    "            found = False\n",
    "            logger.info(f'Waiting for good {k}')\n",
    "            counter = 0\n",
    "            USE_VCC_LOCAL = True\n",
    "            while not found and counter < 5:\n",
    "                counter += 1\n",
    "                if v is None:\n",
    "                    continue\n",
    "                if v.std() > 10:\n",
    "                    found = True\n",
    "                else:\n",
    "                    v = MONITOR[k].get()\n",
    "            if counter == 5:\n",
    "                logger.info(f'VCC is not working. Defaulting to None.')\n",
    "                USE_VCC_LOCAL = False\n",
    "            elif np.ptp(v) < 128:\n",
    "                v = v.astype(np.int8) # Downcast preemptively \n",
    "            pvdata[k] = v\n",
    "        else:\n",
    "            USE_VCC_LOCAL = False\n",
    "\n",
    "    if not USE_VCC_LOCAL and VCC_Key in pvdata:\n",
    "        del pvdata[VCC_Key]\n",
    "\n",
    "    return pvdata, itime, USE_VCC_LOCAL"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EPICS -> Simulation settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_settings(csv, base_settings={}, snapshot_dir=None, snapshot_file=None):\n",
    "    \"\"\"\n",
    "    Fetches live settings for all devices in the CSV table, and translates them to simulation inputs\n",
    "     \n",
    "    \"\"\"\n",
    "    df = DF[DF['device_pv_name'].notna()]\n",
    "    assert len(df) > 0, 'Empty dataframe!'\n",
    "    \n",
    "    pv_names = list(df['device_pv_name'])\n",
    "\n",
    "    pvdata, itime, USE_VCC_LOCAL = get_snapshot(snapshot_file)\n",
    "    \n",
    "    df['pv_value'] = [pvdata[k] for k in pv_names]\n",
    "    \n",
    "    # Assign impact\n",
    "    df['impact_value'] = df['impact_factor']*df['pv_value'] \n",
    "    if 'impact_offset' in df:\n",
    "        df['impact_value'] = df['impact_value']  + df['impact_offset']\n",
    "\n",
    "    # Collect settings\n",
    "    settings = base_settings.copy()\n",
    "    settings.update(dict(zip(df['impact_name'], df['impact_value'])))\n",
    "    \n",
    "    if DEBUG:\n",
    "        settings['total_charge'] = 0\n",
    "    else:\n",
    "        settings['total_charge'] = 1 # Will be updated with particles\n",
    "\n",
    "    # VCC image\n",
    "    if USE_VCC_LOCAL:\n",
    "        logger.info('Getting VCC Live Distgen')\n",
    "        dfile, img, cutimg = get_live_distgen_xy_dist(filename=DISTGEN_LASER_FILE, vcc_device=VCC_DEVICE, pvdata=pvdata)  \n",
    "        settings['distgen:xy_dist:file'] = dfile\n",
    "    else:\n",
    "        img, cutimg = None, None\n",
    "        #settings['distgen:r_dist:max_r:value'] = 0.35 # TEMP     \n",
    "        \n",
    "    if snapshot_dir and not snapshot_file:\n",
    "        filename = os.path.abspath(os.path.join(snapshot_dir, f'{MODEL}-snapshot-{itime}.h5'))\n",
    "        total_charge_pC = settings['distgen:total_charge:value']\n",
    "        if total_charge_pC < MIN_CHARGE_pC:\n",
    "            logger.info(f'total charge is too low: {total_charge_pC:.2f} pC, not saving snapshot')         \n",
    "        else:\n",
    "            save_pvdata(filename, pvdata, itime)\n",
    "            logger.info(f'EPICS shapshot written: {filename}')\n",
    "        \n",
    "        \n",
    "    return settings, df, img, cutimg, itime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DO_TIMING = False\n",
    "\n",
    "if DO_TIMING:\n",
    "    import numpy as np\n",
    "    import time\n",
    "    results = []\n",
    "    tlist = []\n",
    "    nlist = 2**np.arange(1,8, 1)[::-1]\n",
    "    for n in nlist:\n",
    "        t1 = time.time()\n",
    "        LIVE_SETTINGS['numprocs'] = n\n",
    "        print(f'running wit {n}')\n",
    "        result = run_impact_with_distgen(LIVE_SETTINGS, **CONFIG0, verbose=False )\n",
    "        results.append(result)\n",
    "        dt = time.time() - t1\n",
    "        tlist.append(dt)\n",
    "        print(n, dt)     \n",
    "        \n",
    "    tlist, nlist        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get live values, run Impact-T, make dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Patch this into the function below for the dashboard creation\n",
    "def my_merit(impact_object, itime):\n",
    "    # Collect standard output statistics\n",
    "    merit0 = default_impact_merit(impact_object)\n",
    "    \n",
    "    PLOT_OUTPUT_DIR_DATED = convertToDatedFormat(PLOT_OUTPUT_DIR)\n",
    "    #Overriding at runtime to save in dated folders\n",
    "    DASHBOARD_KWARGS[\"outpath\"] = PLOT_OUTPUT_DIR_DATED\n",
    "    \n",
    "    # Make the dashboard from the evaluated object\n",
    "    plot_file = make_dashboard(impact_object, itime=itime, **DASHBOARD_KWARGS)\n",
    "    #print('Dashboard written:', plot_file)\n",
    "    logger.info(f'Dashboard written: {plot_file}')\n",
    "    \n",
    "    # Make all readable\n",
    "    os.chmod(plot_file, 0o644)\n",
    "    \n",
    "    # Assign extra info\n",
    "    merit0['plot_file'] = plot_file    \n",
    "    merit0['isotime'] = itime\n",
    "    \n",
    "    # Clear any buffers\n",
    "    plt.close('all')\n",
    "\n",
    "    return merit0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run1():\n",
    "    dat = {}\n",
    "\n",
    "    SNAPSHOT_DIR_DATED = convertToDatedFormat(SNAPSHOT_DIR)\n",
    "    ARCHIVE_DIR_DATED = convertToDatedFormat(ARCHIVE_DIR)\n",
    "    SUMMARY_OUTPUT_DIR_DATED = convertToDatedFormat(SUMMARY_OUTPUT_DIR)\n",
    "        \n",
    "    # Acquire settings\n",
    "    mysettings, df, img, cutimg, itime = get_settings(CSV,\n",
    "                                                           SETTINGS0,\n",
    "                                                           snapshot_dir=SNAPSHOT_DIR_DATED,\n",
    "                                                          snapshot_file=SNAPSHOT)        \n",
    "    dat['isotime'] = itime\n",
    "    \n",
    "    # Record inputs\n",
    "    dat['inputs'] = mysettings\n",
    "    dat['config'] = CONFIG0\n",
    "    dat['pv_mapping_dataframe'] = df.to_dict()\n",
    "    \n",
    "    logger.info(f'Running evaluate_impact_with_distgen...')\n",
    "\n",
    "    t0 = time()\n",
    "    \n",
    "    total_charge_pC = mysettings['distgen:total_charge:value']\n",
    "    if total_charge_pC < MIN_CHARGE_pC:\n",
    "        logger.info(f'total charge is too low: {total_charge_pC:.2f} pC, skipping')\n",
    "        return dat\n",
    "    \n",
    "    outputs = evaluate_impact_with_distgen(mysettings,\n",
    "                                       merit_f=lambda x: my_merit(x, itime),\n",
    "                                       archive_path=ARCHIVE_DIR_DATED,\n",
    "                                       **CONFIG0, verbose=True )\n",
    "    \n",
    "    dat['outputs'] =  outputs   \n",
    "    logger.info(f'...finished in {(time()-t0)/60:.1f} min')\n",
    "    fname = fname=f'{SUMMARY_OUTPUT_DIR_DATED}/{PREFIX}-{itime}.json'\n",
    "\n",
    "    json.dump(dat, open(fname, 'w'), cls=NpEncoder)\n",
    "    logger.info(f'Summary output written: {fname}')\n",
    "    return dat\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# loop it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    while True:\n",
    "        try:\n",
    "            result = run1()\n",
    "            sleep(10)\n",
    "        except Exception as e:\n",
    "            logger.info(e)\n",
    "            if (e.__class__.__name__ == 'Exception'):\n",
    "                logger.info('Stopping the Program')\n",
    "                break\n",
    "            else:\n",
    "                logger.info('Something BAD happened. Sleeping for 10 s ...')      \n",
    "                sleep(10)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
